{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93428395-64f0-4d5b-a550-fe1a560e1639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "from transformers import BertConfig, BertTokenizer, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b484eaf-b2f5-490f-9027-479a215287f5",
   "metadata": {},
   "source": [
    "## Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77c9f527-e179-4395-a6ed-46b4f0cad180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import BertConfig, BertTokenizer, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "802559ed-85d3-479a-84aa-75803d4f5db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained(\"bert-base-chinese\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e8c01d6-cda2-4647-84a0-3a3653dd2143",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = \"他開車時說話\"\n",
    "sent2 = \"今天他很開心\"\n",
    "sent3 = \"我畫全開海報\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44e85320-3c27-4f87-ae76-330e6608a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sent(sent):\n",
    "    batch = tokenizer(sent, return_tensors=\"pt\")\n",
    "    with torch.no_grad():    \n",
    "        out = model(**batch, output_hidden_states=True)\n",
    "        h = out.hidden_states[-1]\n",
    "        h = h[0, 1:-1].detach().numpy()\n",
    "        h /= np.linalg.norm(h, axis=-1)[:, np.newaxis]\n",
    "        return h\n",
    "enc1 = encode_sent(sent1)\n",
    "enc2 = encode_sent(sent2)\n",
    "enc3 = encode_sent(sent3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76244538-e646-4036-9f32-d76cc5f9d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.family\"]=\"Microsoft YaHei\"\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import cm\n",
    "\n",
    "pca = PCA()\n",
    "proj = pca.fit_transform(np.vstack([enc1, enc2, enc3]))\n",
    "groups = [0]*enc1.shape[0]+[1]*enc2.shape[0]+[2]*enc3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d58d9887-a99a-4196-94e0-25b32e0790fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_frame(frame_idx):\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    chseqs = sent1+sent2+sent3\n",
    "    ch_x = chseqs[frame_idx]\n",
    "    tgt_idxs = [i for i, x in enumerate(chseqs) \n",
    "                if x==\"開\" and frame_idx>=i]\n",
    "    ax.set_xlim(-.75,.75)\n",
    "    ax.set_ylim(-.5,1.0)\n",
    "    cmap = cm.get_cmap('Set1')\n",
    "    plt.scatter(proj[:frame_idx+1,0], \n",
    "                proj[:frame_idx+1,1], \n",
    "                c=[cmap(g) for g in groups[:frame_idx+1]])\n",
    "    \n",
    "    n_sent1 = len(sent1)\n",
    "    n_sent12 = len(sent1)+len(sent2)\n",
    "    n_sent123 = len(groups)\n",
    "    if frame_idx >= 0:\n",
    "        end_idx = min(frame_idx+1, n_sent1)\n",
    "        plt.plot(proj[:end_idx,0], \n",
    "                 proj[:end_idx,1], color=cmap(0))                \n",
    "    if frame_idx >= n_sent1:\n",
    "        end_idx = min(frame_idx+1, n_sent12)\n",
    "        plt.plot(proj[n_sent1:end_idx,0], \n",
    "                 proj[n_sent1:end_idx,1], color=cmap(1))\n",
    "    if frame_idx >= n_sent12:\n",
    "        plt.plot(proj[n_sent12:frame_idx+1,0], \n",
    "                 proj[n_sent12:frame_idx+1,1], color=cmap(2))\n",
    "    \n",
    "    for g_idx, idx in enumerate(tgt_idxs):\n",
    "        circle = plt.Circle((proj[idx,0], proj[idx, 1]), .05, \n",
    "                            facecolor='none', edgecolor=cmap(g_idx), linewidth=3)\n",
    "        ax.add_artist(circle)\n",
    "        \n",
    "    plt.annotate(ch_x, (proj[frame_idx, 0], proj[frame_idx, 1]), fontsize=16)\n",
    "    \n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88423b4c-e5fe-401e-a975-c01cd6c801d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "trace_dir = Path(\"../data/bert_traces\")\n",
    "trace_dir.mkdir(exist_ok=True)\n",
    "for frame_idx in range(len(groups)):\n",
    "    fig = plot_frame(frame_idx)    \n",
    "    fig.savefig((trace_dir/f\"trace_{frame_idx:02d}.jpg\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa5c94-61ae-4b64-b883-0689483cdedc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

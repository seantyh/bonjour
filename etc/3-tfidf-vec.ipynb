{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(Path(\"../data/tlds_data_mc4_tw_000.nlp.json\").read_text(encoding=\"UTF-8\"))\n",
    "train_data, test_data = train_test_split(\n",
    "                          data, test_size=0.2, \n",
    "                          stratify=[x[\"tld\"] for x in data],\n",
    "                          random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'com': 200, 'org': 200, 'gov': 200, 'edu': 200})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([x[\"tld\"] for x in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 28586)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def to_words(item_x):\n",
    "  return [x[0] for x in item_x[\"nlp\"]]\n",
    "tfidf_trans = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False, min_df=1)\n",
    "pipe = Pipeline([\n",
    "      ('scaler', StandardScaler(with_mean=False)), \n",
    "      ('logistic', LogisticRegression(random_state=12345))])\n",
    "X = tfidf_trans.fit_transform([to_words(x) for x in train_data])\n",
    "print(X.shape)\n",
    "y = [x[\"tld\"] for x in train_data]\n",
    "pipe.fit(X,y)\n",
    "pipe.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX = tfidf_trans.transform([to_words(x) for x in test_data])\n",
    "testy = [x[\"tld\"] for x in test_data]\n",
    "pipe.score(testX,testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "com ['購物', '新浪', '情報', '上午點', '商品', '團號', '出發', '天夜', '字級', '電視']\n",
      "edu ['取自', '修訂', '花絮', '夏季班', '研究', '貢獻', '對話', '大學', '參訪', '做']\n",
      "gov ['人次', '瀏覽', '好客', '標籤', '影音', '客家', '平台', '集', '總瀏覽', '政府']\n",
      "org ['推文', '使者', '雜誌', '台灣', '協會', '專欄', '建議', '能源局', '包膜', '鋼化']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "feats = tfidf_trans.get_feature_names_out()\n",
    "clf = pipe[\"logistic\"]\n",
    "for i in range(4):\n",
    "  tld_feat_rank = np.argsort(-clf.coef_[i])\n",
    "  print(clf.classes_[i], [feats[x] for x in tld_feat_rank[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114344"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['com'], dtype='<U3')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = (\"臺灣 大學 生物 資源 暨 農學院 在 區塊鏈 應用 於 智慧 農業 的 技術 上 ， 數年 前 即 「 超前 部署 」 ， \"\n",
    "       \"如今 已 進入 「 數位 農業 創新 知識 履歷 碳 溯源 」 階段 ， 成果 豐碩 ， 預期 知識 區塊鏈 將 會 翻轉 臺灣 農業 的 新 面貌 。\")\n",
    "clf.predict(tfidf_trans.transform([text.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['數年', '「', '」', '「', '」']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## OOVs:\n",
    "[x for x in text.split() if x not in feats]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../data/bonjour-tlds\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"../data/bonjour-tlds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'edu'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "  logits = model(**tokenizer(text.replace(\" \", \"\"), return_tensors=\"pt\")).logits\n",
    "\n",
    "pred = np.argmax(logits, axis=-1)\n",
    "[\"com\", \"edu\", \"gov\", \"org\"][pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
